{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_grid.util import grid_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipw\n",
    "output = ipw.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::UserWarning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ml_grid\n",
    "import pathlib\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ml_grid.util.project_score_save import project_score_save_class\n",
    "\n",
    "base_project_dir_global = 'HFE_ML_h20_experiments/'\n",
    "\n",
    "pathlib.Path(base_project_dir_global).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "st_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%I-%M-%S_%p\")\n",
    "\n",
    "base_project_dir = 'HFE_ML_h20_experiments/' + st_time + \"/\"\n",
    "additional_naming = \"HFE_ML_h20_Grid_\"\n",
    "\n",
    "print(base_project_dir)\n",
    "\n",
    "pathlib.Path(base_project_dir).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "#input_csv_path = '/home/aliencat/samora/HFE/HFE/v20/30163_to_16408_imputed_outcome_grid.csv'\n",
    "\n",
    "input_csv_path = '/home/aliencat/samora/HFE/HFE/v22/hfe_TC_merge_T_Im_10k_1yr_mean_imputed.csv'\n",
    "\n",
    "input_csv_path = '/data/AS/Samora/HFE/HFE/v21/hfe_TC_merge_T_Im_10k_1yr_mean_imputed.csv'\n",
    "\n",
    "input_csv_path = '/data/AS/Samora/HFE/HFE/v24 -h20/hfev_1yr_m_19072023.csv'\n",
    "\n",
    "input_csv_path = '/data/AS/Samora/HFE/HFE/v24 -h20/hfe_TC_merge_mean_Im_10k_1yr_forward_backward_imp_M_nonan.csv'\n",
    "\n",
    "#input_csv_path = '/data/AS/Samora/HFE/HFE/v24 -h20/hfev_1yr_5_to_1_m_19072023.csv'\n",
    "\n",
    "#input_csv_path = 'test_data_hfe_1yr_m_small.csv' #large\n",
    "\n",
    "#init csv to store each local projects results\n",
    "\n",
    "project_score_save_class(base_project_dir)\n",
    "\n",
    "n_iter = 1000\n",
    "\n",
    "grid_iter_obj = grid_param_space.Grid(sample_n=n_iter).settings_list_iterator\n",
    "\n",
    "for i in tqdm(range(0, n_iter)):\n",
    "    if(i%2==0):\n",
    "        #pass\n",
    "        output.clear_output(wait=True)\n",
    "\n",
    "    #get settings from iterator over grid of settings space\n",
    "    local_param_dict = next(grid_iter_obj)\n",
    "\n",
    "    #create object from settings\n",
    "    ml_grid_object = ml_grid.pipeline.data.pipe(input_csv_path,\n",
    "                                                drop_term_list=['chrom', 'hfe', 'phlebo'],\n",
    "                                                local_param_dict=local_param_dict,\n",
    "                                                base_project_dir = base_project_dir,\n",
    "                                                additional_naming = additional_naming,\n",
    "                                                test_sample_n = 0,\n",
    "                                                param_space_index = i\n",
    "                                                \n",
    "                                                )\n",
    "\n",
    "    from ml_grid.pipeline import main\n",
    "\n",
    "\n",
    "    #pass object to be evaluated and write results to csv\n",
    "    res = main.run(ml_grid_object, local_param_dict=local_param_dict).execute()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_grid_object.y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_grid_object.y_test_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".asnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.run(ml_grid_object, local_param_dict=local_param_dict).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree('HFE_ML_h20_experiments/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list == column_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute param grid for all then normalise... for 1:1 for each method\n",
    "\n",
    "#apply max for under util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_grid_object.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values to variables\n",
    "X_train_data = ml_grid_object.X_train\n",
    "y_train_data = ml_grid_object.y_train.to_frame()\n",
    "X_test_data = ml_grid_object.X_test\n",
    "y_test_data = ml_grid_object.y_test.to_frame()\n",
    "X_test_orig_data = ml_grid_object.X_test_orig\n",
    "y_test_orig_data = ml_grid_object.y_test_orig.to_frame()\n",
    "\n",
    "# Create H2OFrame objects using the variables\n",
    "X_train = h2o.H2OFrame(X_train_data)\n",
    "y_train = h2o.H2OFrame(y_train_data)\n",
    "X_test = h2o.H2OFrame(X_test_data)\n",
    "y_test = h2o.H2OFrame(y_test_data)\n",
    "X_test_orig = h2o.H2OFrame(X_test_orig_data)\n",
    "y_test_orig = h2o.H2OFrame(y_test_orig_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_h2o_frame['outcome_var_1'].asnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values to variables\n",
    "X_train_data = ml_grid_object.X_train\n",
    "y_train_data = ml_grid_object.y_train.to_frame()\n",
    "X_test_data = ml_grid_object.X_test\n",
    "y_test_data = ml_grid_object.y_test.to_frame()\n",
    "X_test_orig_data = ml_grid_object.X_test_orig\n",
    "y_test_orig_data = ml_grid_object.y_test_orig.to_frame()\n",
    "\n",
    "# Concatenate train and test data using Pandas\n",
    "train = pd.concat([X_train_data, y_train_data], axis=1)\n",
    "test = pd.concat([X_test_data, y_test_data], axis=1)\n",
    "test_orig = pd.concat([X_test_orig_data, y_test_orig_data], axis=1)\n",
    "\n",
    "train_h2o_frame = h2o.H2OFrame(train)\n",
    "test_h2o_frame = h2o.H2OFrame(test)\n",
    "\n",
    "\n",
    "outcome_variable = 'outcome_var_1'\n",
    "# Identify predictors and response\n",
    "x = list(train.columns)\n",
    "y = outcome_variable\n",
    "x.remove(y)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train_h2o_frame[y] = train_h2o_frame[y].asfactor()\n",
    "test_h2o_frame[y] = test_h2o_frame[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h2o_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_models=2, seed=1)\n",
    "aml.train(x=x, y=y, training_frame=train_h2o_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from AutoML\n",
    "best_model = aml.leader\n",
    "\n",
    "# Make predictions using the best model\n",
    "predictions = best_model.predict(test_h2o_frame)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_grid.model_classes.H2OAutoMLClassifier_wrapper import H2OAutoMLClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2OAutoMLClassifier().fit(train_h2o_frame, test_h2o_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = H2OAutoMLClassifier().fit(X_train_data[X_train_data.columns[0:30]], y_train_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    res,\n",
    "    X_train_data[X_train_data.columns[0:10]],\n",
    "    y_train_data,\n",
    "    scoring=metric_list,\n",
    "    cv=self.cv,\n",
    "    n_jobs=grid_n_jobs,  # Full CV on final best model #exp -1 was 1\n",
    "    pre_dispatch = 80, #exp,\n",
    "    error_score=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = res.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictions['predict'].as_data_frame().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\").as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.iloc[0]['algo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = best_model.model_performance(test_h2o_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.sklearn import H2OAutoMLClassifier\n",
    "\n",
    "# Convert H2O model to Scikit-Learn model\n",
    "sklearn_model = H2OAutoMLClassifier(aml.leader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader.explain(test_h2o_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(aml.leader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader.fit(X_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2OStackedEnsembleEstimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_algorithm = sklearn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = ml_grid_object.X_train\n",
    "y_train_data = ml_grid_object.y_train.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(current_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_algorithm.nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_algorithm.is_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_algorithm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(current_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = eval(str(current_algorithm.show()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_algorithm.fit(X_train_data, y_train_data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import (classification_report, f1_score, make_scorer,\n",
    "                             matthews_corrcoef, roc_auc_score)\n",
    "from sklearn.model_selection import (GridSearchCV, ParameterGrid,\n",
    "                                     RandomizedSearchCV, RepeatedKFold,\n",
    "                                     cross_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = {'auc': make_scorer(roc_auc_score, needs_proba=False),\n",
    "                'f1':'f1',\n",
    "                'accuracy':'accuracy',\n",
    "                'recall': 'recall'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_n_jobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    res,\n",
    "    X_train_data[X_train_data.columns[0:10]],\n",
    "    y_train_data,\n",
    "    scoring=metric_list,\n",
    "    cv=cv,\n",
    "    n_jobs=grid_n_jobs,  # Full CV on final best model #exp -1 was 1\n",
    "    pre_dispatch = 80, #exp,\n",
    "    error_score=np.nan\n",
    ")\n",
    "current_algorithm_scores = scores\n",
    "#     scores_tuple_list.append((method_name, current_algorithm_scores, grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_algorithm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_pred_orig = current_algorithm.predict(self.X_test_orig[self.X_test_orig.columns]) #exp\n",
    "\n",
    "#--------------------\n",
    "\n",
    "predictions = best_model.predict(test_h2o_frame)\n",
    "\n",
    "best_pred_orig = predictions['predict'].as_data_frame().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = best_model.model_performance(train_h2o_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_training_frame = best_model.actual_params['training_frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_training_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_used = h2o.get_frame(my_training_frame)\n",
    "col_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'hfe_TC_merge_T_Im_10k_1yr_mean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_csv('/data/AS/Samora/HFE/HFE/v21/hfe_TC_merge_T_Im_10k_1yr_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['client_idcode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_space(path):\n",
    "    disk_usage = psutil.disk_usage(path)\n",
    "    free_space = disk_usage.free / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "    return free_space\n",
    "\n",
    "device_path = \"/\"  # Change this to the path of the device you're interested in\n",
    "free_space_gb = get_free_space(device_path)\n",
    "print(f\"Free space on {device_path}: {free_space_gb:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_space(path):\n",
    "    disk_usage = psutil.disk_usage(path)\n",
    "    free_space = disk_usage.free / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "    return free_space\n",
    "\n",
    "def get_all_drive_free_space():\n",
    "    all_partitions = psutil.disk_partitions(all=True)\n",
    "    \n",
    "    for partition in all_partitions:\n",
    "        device_path = partition.mountpoint\n",
    "        free_space_gb = get_free_space(device_path)\n",
    "        print(f\"Free space on {device_path}: {free_space_gb:.2f} GB\")\n",
    "\n",
    "get_all_drive_free_space()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_space_percentage(path):\n",
    "    disk_usage = psutil.disk_usage(path)\n",
    "    total_capacity = disk_usage.total\n",
    "    \n",
    "    if total_capacity == 0:\n",
    "        return 0.0  # Handle the case of zero total capacity\n",
    "    \n",
    "    free_space_percentage = (disk_usage.free / total_capacity) * 100\n",
    "    return free_space_percentage\n",
    "\n",
    "def get_all_drive_free_space_percentage():\n",
    "    all_partitions = psutil.disk_partitions(all=True)\n",
    "    \n",
    "    for partition in all_partitions:\n",
    "        device_path = partition.mountpoint\n",
    "        free_space_percentage = get_free_space_percentage(device_path)\n",
    "        print(f\"Free space on {device_path}: {free_space_percentage:.2f}%\")\n",
    "\n",
    "get_all_drive_free_space_percentage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_files_info(directory_path):\n",
    "    files_info = []\n",
    "\n",
    "    for root, dirs, files in tqdm(os.walk(directory_path)):\n",
    "        for file in (files):\n",
    "            try:\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_size = os.path.getsize(file_path)\n",
    "                files_info.append({\n",
    "                    'File Name': file,\n",
    "                    'File Path': file_path,\n",
    "                    'File Size (bytes)': file_size\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return files_info\n",
    "\n",
    "directory_path = '/data/AS/Samora'\n",
    "files_info = get_files_info(directory_path)\n",
    "df = pd.DataFrame(files_info)\n",
    "\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_sizes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('File Size (bytes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('File Size (bytes)').tail(50\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"File '{file_path}' deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting '{file_path}': {e}\")\n",
    "\n",
    "file_to_delete = '/data/AS/Samora/CLL/fin_Tests_controls.csv'  # Replace with the actual file path\n",
    "delete_file(file_to_delete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    try:\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting '{folder_path}': {e}\")\n",
    "\n",
    "folder_to_delete = '/data/AS/Samora/pregnancy_cardio/Pregnancy_documents'  # Replace with the actual folder path\n",
    "delete_folder(folder_to_delete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class h2o_evaluate_class():\n",
    "    \n",
    "    \n",
    "    def __init__(self, algorithm_implementation, parameter_space, method_name, ml_grid_object, sub_sample_parameter_val = 100): # kwargs**\n",
    "        #\n",
    "        \n",
    "        warnings.filterwarnings('ignore') \n",
    "\n",
    "        warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "        warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "        \n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        \n",
    "        h2o.init()\n",
    "        \n",
    "        self.global_params = global_parameters()\n",
    "        \n",
    "        self.verbose = self.global_params.verbose\n",
    "        \n",
    "        self.sub_sample_param_space_pct = self.global_params.sub_sample_param_space_pct\n",
    "        \n",
    "        random_grid_search = self.global_params.random_grid_search\n",
    "        \n",
    "        self.sub_sample_parameter_val = sub_sample_parameter_val\n",
    "        \n",
    "        grid_n_jobs = self.global_params.grid_n_jobs\n",
    "        \n",
    "        \n",
    "        self.metric_list = self.global_params.metric_list\n",
    "        \n",
    "        self.error_raise = self.global_params.error_raise\n",
    "        \n",
    "        \n",
    "        if(self.verbose >=3):\n",
    "            print(f\"crossvalidating {method_name}\")\n",
    "        \n",
    "        self.global_parameters = global_parameters()\n",
    "        \n",
    "        self.ml_grid_object_iter = ml_grid_object\n",
    "        \n",
    "        self.X_train = h2o.H2OFrame(self.ml_grid_object_iter.X_train)\n",
    "        self.y_train = h2o.H2OFrame(self.ml_grid_object_iter.y_train.to_frame())\n",
    "        self.X_test = h2o.H2OFrame(self.ml_grid_object_iter.X_test)\n",
    "        self.y_test = h2o.H2OFrame(self.ml_grid_object_iter.y_test.to_frame())\n",
    "        self.X_test_orig = h2o.H2OFrame(self.ml_grid_object_iter.X_test_orig)\n",
    "        self.y_test_orig = h2o.H2OFrame(self.ml_grid_object_iter.y_test_orig.to_frame())\n",
    "\n",
    "        \n",
    "        self.nfolds_val = -1 #auto\n",
    "        \n",
    "        \n",
    "        # Assign values to variables\n",
    "        X_train_data = ml_grid_object.X_train\n",
    "        y_train_data = ml_grid_object.y_train.to_frame()\n",
    "        X_test_data = ml_grid_object.X_test\n",
    "        y_test_data = ml_grid_object.y_test.to_frame()\n",
    "        X_test_orig_data = ml_grid_object.X_test_orig\n",
    "        y_test_orig_data = ml_grid_object.y_test_orig.to_frame()\n",
    "\n",
    "        # Concatenate train and test data using Pandas\n",
    "        train = pd.concat([X_train_data, y_train_data], axis=1)\n",
    "        test = pd.concat([X_test_data, y_test_data], axis=1)\n",
    "        test_orig = pd.concat([X_test_orig_data, y_test_orig_data], axis=1)\n",
    "\n",
    "        train_h2o_frame = h2o.H2OFrame(train)\n",
    "        test_h2o_frame = h2o.H2OFrame(test)\n",
    "\n",
    "\n",
    "        outcome_variable = 'outcome_var_1'\n",
    "        \n",
    "        outcome_variable = y_train_data.columns[0]\n",
    "        # Identify predictors and response\n",
    "        x = list(train.columns)\n",
    "        y = outcome_variable\n",
    "        x.remove(y)\n",
    "\n",
    "        # For binary classification, response should be a factor\n",
    "        train_h2o_frame[y] = train_h2o_frame[y].asfactor()#.asnumeric()\n",
    "        test_h2o_frame[y] = test_h2o_frame[y].asfactor()#.asnumeric()\n",
    "        \n",
    "        \n",
    "        #self.cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " \n",
    "        start = time.time()\n",
    "\n",
    "    \n",
    "        aml = H2OAutoML(max_models=5, seed=1)\n",
    "        aml.train(x=x, y=y, training_frame=train_h2o_frame)\n",
    "        \n",
    "        \n",
    "        h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\")\n",
    "\n",
    "        if(self.global_parameters.verbose >= 4):\n",
    "            \n",
    "            debug_print_statements_class.debug_print_scores(scores)\n",
    "            \n",
    "        plot_auc = False\n",
    "        if(plot_auc):    \n",
    "\n",
    "            print(\" \")\n",
    "            \n",
    "            \n",
    "        best_model = aml.leader\n",
    "            \n",
    "        \n",
    "        \n",
    "        performance = best_model.model_performance(test_h2o_frame)\n",
    "        \n",
    "        \n",
    "    \n",
    "        #--------------------\n",
    "\n",
    "        \n",
    "        self.cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        # global scores_tuple_list\n",
    "        # global i\n",
    "        start = time.time()\n",
    "\n",
    "        current_algorithm = algorithm_implementation\n",
    "\n",
    "        parameters = parameter_space\n",
    "        n_iter_v = np.nan\n",
    "\n",
    "        sklearn_model = H2OAutoMLClassifier(aml.leader)\n",
    "        \n",
    "        current_algorithm = sklearn_model\n",
    "        \n",
    "        \n",
    "        current_algorithm.fit(self.X_train, self.y_train)\n",
    "            \n",
    "\n",
    "        scores = cross_validate(\n",
    "            current_algorithm,\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            scoring=metric_list,\n",
    "            cv=self.cv,\n",
    "            n_jobs=grid_n_jobs,  # Full CV on final best model #exp -1 was 1\n",
    "            pre_dispatch = 80, #exp,\n",
    "            error_score=np.nan\n",
    "        )\n",
    "        current_algorithm_scores = scores\n",
    "    #     scores_tuple_list.append((method_name, current_algorithm_scores, grid))\n",
    "        \n",
    "\n",
    "        #best_pred_orig = current_algorithm.predict(self.X_test_orig[self.X_test_orig.columns]) #exp\n",
    "\n",
    "        #--------------------\n",
    "        \n",
    "        predictions = best_model.predict(test_h2o_frame)\n",
    "        \n",
    "        best_pred_orig = predictions['predict'].as_data_frame().values\n",
    "        \n",
    "        \n",
    "        pg = np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data using Pandas\n",
    "train = pd.concat([X_train_data, y_train_data], axis=1)\n",
    "test = pd.concat([X_test_data, y_test_data], axis=1)\n",
    "test_orig = pd.concat([X_test_orig_data, y_test_orig_data], axis=1)\n",
    "\n",
    "train_h2o_frame = h2o.H2OFrame(train)\n",
    "test_h2o_frame = h2o.H2OFrame(test)\n",
    "\n",
    "\n",
    "outcome_variable = 'outcome_var_1'\n",
    "# Identify predictors and response\n",
    "x = list(train.columns)\n",
    "y = outcome_variable\n",
    "x.remove(y)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train_h2o_frame[y] = train_h2o_frame[y].asfactor()\n",
    "test_h2o_frame[y] = test_h2o_frame[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2OAutoMLClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_runtime_secs=60, nfolds=5, seed=1):\n",
    "        self.max_runtime_secs = max_runtime_secs\n",
    "        self.nfolds = nfolds\n",
    "        self.seed = seed\n",
    "        self.automl = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #X, y = check_X_y(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        outcome_var = y_train_data.columns[0]\n",
    "        \n",
    "        x = list(train.columns)\n",
    "        y_n = outcome_var\n",
    "        x.remove(y_n)\n",
    "        \n",
    "        h2o.init()\n",
    "        #train_df = pd.concat([pd.DataFrame(X), pd.Series(y)], axis=1)\n",
    "        \n",
    "        train_df = pd.concat([X, y], axis=1)\n",
    "        \n",
    "        \n",
    "        train_h2o = h2o.H2OFrame(train_df)\n",
    "        \n",
    "        train_h2o[y_n] = train_h2o[y_n].asfactor()\n",
    "        \n",
    "        self.automl = H2OAutoML(max_runtime_secs=self.max_runtime_secs, nfolds=self.nfolds, seed=self.seed)\n",
    "        self.automl.train(y=y_n, x=x, training_frame=train_h2o)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        #X = check_array(X)\n",
    "        #test_h2o = h2o.H2OFrame(pd.DataFrame(X))\n",
    "        test_h2o = h2o.H2OFrame(X)\n",
    "        predictions = self.automl.leader.predict(test_h2o)\n",
    "        \n",
    "        return predictions[:,0]\n",
    "        #return predictions.as_data_frame().values\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        raise NotImplementedError(\"H2O AutoML does not support predict_proba.\")\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"max_runtime_secs\": self.max_runtime_secs,\n",
    "            \"nfolds\": self.nfolds,\n",
    "            \"seed\": self.seed,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_automl = H2OAutoMLClassifier(max_runtime_secs=10)\n",
    "h2o_automl.fit(X_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = h2o_automl.predict(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = h2o_automl.predict(X_test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_data, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tef_env3",
   "language": "python",
   "name": "tef_env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8950ac4cfc931727e24d24f4b808543239b03da116b018555b940ef0843a8cf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}